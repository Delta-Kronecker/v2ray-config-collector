name: Automated Proxy Collection and Testing

on:
  schedule:
    # Run every 12 hours at 00:00 and 12:00 UTC
    - cron: '0 0,12 * * *'
  workflow_dispatch: # Allow manual triggering

permissions:
  contents: write
  actions: read

jobs:
  proxy-collection-and-testing:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python 3.x
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Python dependencies
      run: |
        echo "Installing required Python packages..."
        pip install tenacity requests
        echo "Python dependencies installed successfully"

    - name: Set up Go 1.23
      uses: actions/setup-go@v4
      with:
        go-version: '1.23'

    - name: Install Xray
      run: |
        echo "Installing Xray..."
        # Download and extract
        wget -q https://github.com/XTLS/Xray-core/releases/latest/download/Xray-linux-64.zip -O xray.zip
        unzip -q xray.zip
        chmod +x xray
        sudo mv xray /usr/local/bin/
        # Verify
        xray version
        echo "Xray installed successfully"

    - name: Install Go dependencies
      run: |
        cd xray_test
        go mod download
        go mod verify

    - name: Clear and prepare data folder
      run: |
        echo "Clearing and preparing data folder..."
        if [ -d "data" ]; then
          rm -rf data/*
        else
          mkdir -p data
        fi
        # Create all necessary subdirectories
        mkdir -p data/working_json data/working_url data/quality_results data/speed_results data/deduplicated_urls
        echo "Created directory structure:"
        find data -type d

    - name: Execute Python proxy collector
      id: python-collector
      run: |
        echo "Starting Python proxy collection..."
        cd config_collector
        python main.py
        echo "Python proxy collection completed"
      continue-on-error: true

    - name: Execute Go proxy tester
      id: go-proxy-tester
      run: |
        echo "Starting Go proxy connectivity testing..."
        cd xray_test
        go run proxy-tester.go || echo "Proxy tester completed (may have timed out)"
        echo "Go proxy testing completed"
      continue-on-error: true

    - name: Execute Go quality tester
      id: go-quality-tester
      run: |
        echo "Starting Go proxy quality testing..."
        cd xray_test
        go run quality_tester.go || echo "Quality tester completed (may have timed out)"
        echo "Go quality testing completed"
      continue-on-error: true

    - name: Execute Go speed tester
      id: go-speed-tester
      run: |
        echo "Starting Go proxy speed testing..."
        cd xray_test
        go run speed_tester.go || echo "Speed tester completed (may have timed out)"
        echo "Go speed testing completed"
      continue-on-error: true

    - name: Check for xray_test data and move files
      run: |
        echo "Checking for files in xray_test/data..."
        if [ -d "xray_test/data" ]; then
          echo "Found xray_test/data directory, moving files to main data directory..."
          # Move all files from xray_test/data to data/
          mv xray_test/data/* data/ 2>/dev/null || echo "No files to move or already moved"
          # Remove empty directory
          rm -rf xray_test/data 2>/dev/null || true
        else
          echo "xray_test/data directory not found"
        fi

    - name: Comprehensive file check
      run: |
        echo "=== COMPREHENSIVE FILE CHECK ==="
        echo "Current working directory: $(pwd)"
        echo "=== Data directory contents ==="
        if [ -d "data" ]; then
          find data -type f | head -50
          echo "=== File counts by type ==="
          echo "Working JSON: $(find data/working_json -type f 2>/dev/null | wc -l || echo 0)"
          echo "Working URL: $(find data/working_url -type f 2>/dev/null | wc -l || echo 0)"
          echo "Quality results: $(find data/quality_results -type f 2>/dev/null | wc -l || echo 0)"
          echo "Speed results: $(find data/speed_results -type f 2>/dev/null | wc -l || echo 0)"
          echo "Deduplicated URLs: $(find data/deduplicated_urls -type f 2>/dev/null | wc -l || echo 0)"
          echo "Total files in data: $(find data -type f | wc -l)"
        else
          echo "Data folder not found!"
        fi

    - name: Commit and push ALL changes
      run: |
        echo "Checking for changes in all data subdirectories..."

        # Configure git for automated commits
        git config --global user.name 'github-actions[bot]'
        git config --global user.email 'github-actions[bot]@users.noreply.github.com'

        # Fetch latest changes BEFORE adding files
        echo "Fetching latest changes from remote..."
        git fetch origin

        # Check if we're behind remote and pull if needed
        LOCAL=$(git rev-parse HEAD)
        REMOTE=$(git rev-parse origin/${{ github.ref_name }})
        
        if [ "$LOCAL" != "$REMOTE" ]; then
          echo "Local branch is behind remote, pulling changes..."
          git pull --rebase origin "${{ github.ref_name }}" || {
            echo "Rebase failed, trying merge instead..."
            git pull origin "${{ github.ref_name }}"
          }
        fi

        # Add all data subdirectories explicitly
        git add data/ || true
        git add data/working_json/ || true
        git add data/working_url/ || true
        git add data/quality_results/ || true
        git add data/speed_results/ || true
        git add data/deduplicated_urls/ || true

        echo "Files to be committed:"
        git diff --cached --name-only || echo "No files to commit"

        if git diff --cached --quiet; then
          echo "No changes to commit"
        else
          echo "Changes detected, committing..."

          # Create commit message with execution summary
          TIMESTAMP=$(date -u '+%Y-%m-%d %H:%M:%S UTC')
          PYTHON_STATUS="${{ steps.python-collector.outcome }}"
          PROXY_STATUS="${{ steps.go-proxy-tester.outcome }}"
          QUALITY_STATUS="${{ steps.go-quality-tester.outcome }}"
          SPEED_STATUS="${{ steps.go-speed-tester.outcome }}"
          RUN_ID="${{ github.run_id }}"
          GITHUB_REF_NAME="${{ github.ref_name }}"

          git commit -m "Automated proxy collection - ${TIMESTAMP}" \
                     -m "Python Collector: ${PYTHON_STATUS}" \
                     -m "Proxy Tester: ${PROXY_STATUS}" \
                     -m "Quality Tester: ${QUALITY_STATUS}" \
                     -m "Speed Tester: ${SPEED_STATUS}" \
                     -m "Workflow run: ${RUN_ID}"

          # Push with retry logic
          MAX_RETRIES=3
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if git push origin "${GITHUB_REF_NAME}"; then
              echo "âœ… Changes committed and pushed successfully"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              echo "Push failed, attempt $RETRY_COUNT of $MAX_RETRIES"
              
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "Fetching latest changes and retrying..."
                git fetch origin
                git pull --rebase origin "${GITHUB_REF_NAME}" || {
                  echo "Rebase failed, trying merge..."
                  git pull origin "${GITHUB_REF_NAME}"
                }
              else
                echo "âŒ Failed to push after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
        fi

    - name: Upload all results as artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: proxy-results-${{ github.run_id }}
        path: |
          data/working_json/
          data/working_url/
          data/quality_results/
          data/speed_results/
          data/deduplicated_urls/
        retention-days: 7

    - name: Workflow summary
      if: always()
      run: |
        echo "## ðŸ¤– Automated Proxy Collection Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Execution Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Workflow Run:** [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Script Execution Status" >> $GITHUB_STEP_SUMMARY
        echo "| Script | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Python Collector | ${{ steps.python-collector.outcome == 'success' && 'âœ… Success' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Go Proxy Tester | ${{ steps.go-proxy-tester.outcome == 'success' && 'âœ… Success' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Go Quality Tester | ${{ steps.go-quality-tester.outcome == 'success' && 'âœ… Success' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Go Speed Tester | ${{ steps.go-speed-tester.outcome == 'success' && 'âœ… Success' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        if [ -d "data" ]; then
          echo "### Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Result Type | File Count |" >> $GITHUB_STEP_SUMMARY
          echo "|-------------|------------|" >> $GITHUB_STEP_SUMMARY
          echo "| Working JSON | $(find data/working_json -type f 2>/dev/null | wc -l || echo 0) |" >> $GITHUB_STEP_SUMMARY
          echo "| Working URL | $(find data/working_url -type f 2>/dev/null | wc -l || echo 0) |" >> $GITHUB_STEP_SUMMARY
          echo "| Quality Results | $(find data/quality_results -type f 2>/dev/null | wc -l || echo 0) |" >> $GITHUB_STEP_SUMMARY
          echo "| Speed Results | $(find data/speed_results -type f 2>/dev/null | wc -l || echo 0) |" >> $GITHUB_STEP_SUMMARY
          echo "| Deduplicated URLs | $(find data/deduplicated_urls -type f 2>/dev/null | wc -l || echo 0) |" >> $GITHUB_STEP_SUMMARY
          echo "| **Total Files** | **$(find data -type f | wc -l)** |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Data Quality Metrics" >> $GITHUB_STEP_SUMMARY
          
          # Add quality metrics if files exist
          if [ -f "data/quality_results/summary.txt" ]; then
            echo "#### Quality Summary" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat data/quality_results/summary.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f "data/speed_results/speed_summary.txt" ]; then
            echo "#### Speed Summary" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat data/speed_results/speed_summary.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "### âš ï¸ No Data Generated" >> $GITHUB_STEP_SUMMARY
          echo "No data directory found. Check the execution logs for errors." >> $GITHUB_STEP_SUMMARY
        fi